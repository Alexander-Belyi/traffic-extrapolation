{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import glob\n",
    "\n",
    "from typing import Tuple, Union, List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "from src.utils import *\n",
    "from dataset import *\n",
    "from src.train import train, test\n",
    "from src.dataloaders import make_dataloaders_from_dataset\n",
    "from src.model import KnnEstimator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.readwrite.read_gpickle('data/network.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 972], id=[373], lat=[373], lon=[373], labor_force_rate=[373], housing_sales_num_Total:=[373], housing_sales_num_Total:!!Less than $10,000=[373], housing_sales_num_Total:!!$10,000 to $14,999=[373], housing_sales_num_Total:!!$15,000 to $19,999=[373], housing_sales_num_Total:!!$20,000 to $24,999=[373], housing_sales_num_Total:!!$25,000 to $29,999=[373], housing_sales_num_Total:!!$30,000 to $34,999=[373], housing_sales_num_Total:!!$35,000 to $39,999=[373], housing_sales_num_Total:!!$40,000 to $49,999=[373], housing_sales_num_Total:!!$50,000 to $59,999=[373], housing_sales_num_Total:!!$60,000 to $69,999=[373], housing_sales_num_Total:!!$70,000 to $79,999=[373], housing_sales_num_Total:!!$80,000 to $89,999=[373], housing_sales_num_Total:!!$90,000 to $99,999=[373], housing_sales_num_Total:!!$100,000 to $124,999=[373], housing_sales_num_Total:!!$125,000 to $149,999=[373], housing_sales_num_Total:!!$150,000 to $174,999=[373], housing_sales_num_Total:!!$175,000 to $199,999=[373], housing_sales_num_Total:!!$200,000 to $249,999=[373], housing_sales_num_Total:!!$250,000 to $299,999=[373], housing_sales_num_Total:!!$300,000 to $399,999=[373], housing_sales_num_Total:!!$400,000 to $499,999=[373], housing_sales_num_Total:!!$500,000 to $749,999=[373], housing_sales_num_Total:!!$750,000 to $999,999=[373], housing_sales_num_Total:!!$1,000,000 to $1,499,999=[373], housing_sales_num_Total:!!$1,500,000 to $1,999,999=[373], housing_sales_num_Total:!!$2,000,000 or more=[373], median_income=[373],  population=[373],  population!!AGE!!Under 5 years=[373],  population!!AGE!!5 to 9 years=[373],  population!!AGE!!10 to 14 years=[373],  population!!AGE!!15 to 19 years=[373],  population!!AGE!!20 to 24 years=[373],  population!!AGE!!25 to 29 years=[373],  population!!AGE!!30 to 34 years=[373],  population!!AGE!!35 to 39 years=[373],  population!!AGE!!40 to 44 years=[373],  population!!AGE!!45 to 49 years=[373],  population!!AGE!!50 to 54 years=[373],  population!!AGE!!55 to 59 years=[373],  population!!AGE!!60 to 64 years=[373],  population!!AGE!!65 to 69 years=[373],  population!!AGE!!70 to 74 years=[373],  population!!AGE!!75 to 79 years=[373],  population!!AGE!!80 to 84 years=[373],  population!!AGE!!85 years and over=[373], dist=[972], num_nodes=373)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch geometric Data object. For now used only for storing node embedding. \n",
    "# Supposed to be used in the future for obtaining node embeddings.\n",
    "pyg_graph = from_networkx(G)\n",
    "pyg_graph.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$T(a) = \\sum_{b \\neq a,\\space b\\subset Train } T(b)w(a, b), \\textrm{where summation is calculated for the {\\bf k} nearest neighbors.}$$\n",
    "\n",
    "$$ w(a,b)= \\frac{u(a,b)}{\\sum_{b \\neq a} u(a, b)};$$\n",
    "\n",
    "$u(a, b) = exp(-\\lambda_1 d(a, b));$\n",
    "\n",
    "So for this model $\\lambda_1$ is optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def weight_fn(dists, lamb):\n",
    "    return torch.exp(-lamb * dists)\n",
    "\n",
    "\n",
    "class Estimator(KnnEstimator):\n",
    "    def __init__(self, pyg_graph: pyg.data.Data, obs_nodes, obs_targets) -> None:\n",
    "        super().__init__(pyg_graph, obs_nodes, obs_targets)\n",
    "\n",
    "        # self.k = torch.tensor([1.0]).to(device)\n",
    "        self.lambda_1 = nn.Parameter(torch.rand(1))\n",
    "        self.lambda_2 = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # getting nearest observed nodes\n",
    "        X_indices = torch.as_tensor(self.node_to_idx(X))\n",
    "        dists, indices = self.get_kneighbors(X_indices)\n",
    "        \n",
    "        dists = dists.to(device)\n",
    "        indices = indices.to(device)\n",
    "\n",
    "        dist_weights = weight_fn(dists, self.lambda_1)\n",
    "\n",
    "        # sum normalizization\n",
    "        dist_weights = nn.functional.normalize(dist_weights, p=1)\n",
    "\n",
    "        att_weights = dist_weights\n",
    "        targets = self.obs_targets[indices].to(device)\n",
    "\n",
    "        # interpolation \n",
    "        result = torch.sum(att_weights.mul(targets), dim=-1)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46cba9f15864f7d9ee9960fae821eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-03, Test loss: 233.1693, test score: -1.7048\n",
      "2021-01-15, Test loss: 810.1702, test score: -0.3000\n",
      "2021-01-04, Test loss: 603.0308, test score: -2.3722\n",
      "2021-01-24, Test loss: 253.3502, test score: -1.4160\n",
      "2020-12-28, Test loss: 531.8792, test score: -2.2469\n",
      "2021-01-06, Test loss: 583.0620, test score: -2.1916\n",
      "2021-01-13, Test loss: 568.6688, test score: -2.0083\n",
      "2021-01-09, Test loss: 370.2094, test score: -1.1074\n",
      "2021-01-20, Test loss: 360.3887, test score: -0.5112\n",
      "2021-01-18, Test loss: 215.8270, test score: 0.1417\n",
      "2021-01-17, Test loss: 165.5557, test score: -0.0859\n",
      "2021-01-12, Test loss: 268.3489, test score: 0.0378\n",
      "2020-12-29, Test loss: 280.6115, test score: -0.0101\n",
      "2021-01-07, Test loss: 283.6414, test score: -0.0244\n",
      "2020-12-30, Test loss: 275.1746, test score: 0.1108\n",
      "2021-01-19, Test loss: 326.5425, test score: -0.2836\n",
      "mean, Test loss: 332.8162, test score: -0.0803\n",
      "2021-01-02, Test loss: 261.2631, test score: 0.0421\n",
      "2021-01-05, Test loss: 268.4191, test score: 0.1091\n",
      "2020-12-26, Test loss: 133.6624, test score: -0.0314\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.HuberLoss(delta=20).to(device)\n",
    "model = None\n",
    "\n",
    "for path in tqdm(glob.glob('datasets/*')[:20]):\n",
    "    day = path.split('/')[1].split('.')[0]\n",
    "\n",
    "    try:\n",
    "        ds = torch.load(path)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    train_loader, val_loader, test_loader = make_dataloaders_from_dataset(ds, batch_size=16)\n",
    "    train_batches = [batch for batch in train_loader]\n",
    "    train_nodes = [n for batch in train_batches for n in batch[0]]\n",
    "    train_targets = torch.cat([batch[1] for batch in train_batches])\n",
    "\n",
    "\n",
    "    if model is None:\n",
    "        model = Estimator(pyg_graph, train_nodes, train_targets).to(device)\n",
    "    else:\n",
    "        model.set_observations(train_nodes, train_targets)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 20, gamma=0.9)\n",
    "\n",
    "    best_model = train(model, train_loader, val_loader, loss_fn, optimizer, device, num_epochs=10, plotting=False)\n",
    "    test_loss, test_score = test(best_model, test_loader, loss_fn, device)\n",
    "\n",
    "    # for name, param in best_model.named_parameters():\n",
    "        # print(name, param)\n",
    "\n",
    "    results[f'{day}'] = test_score \n",
    "    print(f'{day}, Test loss: {test_loss:.4f}, test score: {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('results/baseline.json', mode='w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30452e0fb0b877c71442cfddf3db9e1b032e1699292a3dd400d9a1b61508e43d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('traffic': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
